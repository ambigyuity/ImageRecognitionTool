from object_detection.utils import label_map_util
from object_detection.utils import visualization_utils as viz_utils
from object_detection.utils import ops as utils_ops
import os
import pathlib
import cv2
import numpy as np
from six import BytesIO
from PIL import Image, ImageDraw, ImageFont
from six.moves.urllib.request import urlopen
import tensorflow as tf
import tensorflow_hub as hub
from converter import Converter

print(tf.__version__)

def cameraInput(model):
    cv2.namedWindow("SAMSAN TECH")
    vc = cv2.VideoCapture(0, cv2.CAP_DSHOW)
    print(vc)

    if vc.isOpened():  # try to get the first frame
        rval, frame = vc.read()
    else:
        rval = False

    converter= Converter()
    converter.convert('mscoco_label_map.pbtxt')
    category_index= converter.getCategoryIndex()
    #print(category_index)

    while rval:
        cv2.imshow("SAMSAN TECH", frame)
        # TODO: MODEL.PREDICT(IMAGE) predict image shown

        im = Image.fromarray(frame, 'RGB')
        (im_width, im_height) = im.size
        ImageArray= np.array(im.getdata()).reshape((1, im_height, im_width, 3)).astype(np.uint8)
        image_np_with_detections = ImageArray.copy()
        results = hub_model(ImageArray)
        result = {key: value.numpy() for key, value in results.items()}

        label_id_offset = 0

        keypoints, keypoint_scores = None, None
        if 'detection_keypoints' in result:
            keypoints = result['detection_keypoints'][0]
            keypoint_scores = result['detection_keypoint_scores'][0]

        #category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)
        #category_index = {1: {'id': 1, 'name': 'person'}}


        #category_index = converter.getCategoryIndex()
        viz_utils.visualize_boxes_and_labels_on_image_array(
            image_np_with_detections[0],
            result['detection_boxes'][0],
            (result['detection_classes'][0] + label_id_offset).astype(int),
            result['detection_scores'][0],
            category_index,
            use_normalized_coordinates=True,
            max_boxes_to_draw=3,
            min_score_thresh=.50,
            agnostic_mode=False,
            keypoints=keypoints)

        cv2.imshow("SAMSAN TECH", image_np_with_detections[0])

        rval, frame = vc.read()
        key = cv2.waitKey(20)
        if key == 27:  # exit on ESC
            break

    vc.release()
    cv2.destroyWindow("preview")
    #model.summary()



model_handle = 'https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2'
print('Model Handle at TensorFlow Hub: {}'.format(model_handle))

print('loading model...')
hub_model = hub.load(model_handle)
print('model loaded!')

print(hub_model.signatures.keys())
detector = hub_model.signatures['serving_default']
cameraInput(hub_model)
